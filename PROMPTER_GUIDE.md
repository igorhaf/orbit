# ğŸ“˜ Guia PrÃ¡tico: Arquitetura Prompter

**Orbit 2.1 - Sistema AvanÃ§ado de Gerenciamento de Prompts**

## ğŸ¯ VisÃ£o Geral

O Prompter Ã© uma arquitetura modular para gerenciamento de prompts de IA que oferece:

- **60-90% de reduÃ§Ã£o de custos** via token reduction e caching
- **Retry automÃ¡tico** com exponential backoff
- **ValidaÃ§Ã£o de qualidade** com 5 validators
- **4 estratÃ©gias de execuÃ§Ã£o** (cost/quality/speed/balanced)
- **Zero downtime migration** via feature flags

---

## ğŸš€ Quick Start

### 1. Habilitar Features

```bash
# Habilitar templates (token reduction)
export PROMPTER_USE_TEMPLATES=true

# Habilitar cache (cost reduction)
export PROMPTER_USE_CACHE=true

# Reiniciar backend
docker-compose restart backend
```

### 2. Verificar Status

```python
from app.prompter.facade import PrompterFacade
from app.database import get_db

db = next(get_db())
facade = PrompterFacade(db)

# Ver status completo
status = facade.get_status()
print(status)

# Output:
{
  "feature_flags": {
    "use_templates": True,
    "use_cache": True,
    "use_batching": False,
    "use_tracing": False
  },
  "components": {
    "composer_loaded": True,
    "executor_loaded": True,
    "cache_loaded": True,
    "model_selector_loaded": True
  },
  "cache_stats": {
    "total_requests": 0,
    "cache_hits": 0,
    "hit_rate": 0.0,
    "hit_rate_percent": "0.0%"
  },
  "available_models": [
    "claude-sonnet-4",
    "claude-haiku-3",
    "gpt-4o",
    "gemini-flash"
  ]
}
```

---

## ğŸ“ Casos de Uso

### Caso 1: GeraÃ§Ã£o de Tasks (Com Templates)

```python
from app.prompter.facade import PrompterFacade
from app.models.project import Project

facade = PrompterFacade(db)

# Gerar prompt usando template
conversation = [
    {"role": "user", "content": "Quero criar um e-commerce"},
    {"role": "assistant", "content": "Que tipo de produtos?"},
    {"role": "user", "content": "Roupas e acessÃ³rios"}
]

project = db.query(Project).first()
specs = {"backend": [...], "frontend": [...]}

# Usa template YAML automaticamente
prompt = facade.generate_task_prompt(
    conversation=conversation,
    project=project,
    specs=specs
)

# Prompt gerado com:
# - Token reduction (referencia specs ao invÃ©s de reproduzir)
# - Formato consistente
# - ValidaÃ§Ã£o de variÃ¡veis
```

### Caso 2: ExecuÃ§Ã£o com Cache e Retry

```python
# Executar prompt com orquestraÃ§Ã£o completa
result = await facade.execute_prompt(
    prompt="Generate tasks for e-commerce project",
    usage_type="task_generation",
    strategy="cost",  # Otimizar para custo
    max_tokens=4000,
    temperature=0.7,
    project_id=project.id
)

print(f"âœ… Response: {result['response'][:100]}...")
print(f"ğŸ’° Cost: ${result['cost']:.4f}")
print(f"âš¡ Cache hit: {result['cache_hit']}")
print(f"ğŸ¤– Model: {result['model']}")
print(f"â­ Quality score: {result['quality_score']:.2f}")
print(f"â±ï¸  Duration: {result['duration_seconds']:.2f}s")
print(f"ğŸ”„ Attempts: {result['attempt']}")

# Output exemplo:
# âœ… Response: {"tasks": [{"title": "Setup Laravel project"...
# ğŸ’° Cost: $0.0123
# âš¡ Cache hit: False
# ğŸ¤– Model: gemini-flash
# â­ Quality score: 0.92
# â±ï¸  Duration: 1.45s
# ğŸ”„ Attempts: 1
```

### Caso 3: Diferentes EstratÃ©gias

```python
# ESTRATÃ‰GIA 1: Cost-Optimized (mais barato)
result_cost = await facade.execute_prompt(
    prompt=prompt,
    strategy="cost",  # Gemini Flash, cache-first, 2 attempts
    usage_type="task_generation"
)
# â†’ Model: gemini-flash
# â†’ Cost: ~$0.001
# â†’ Latency: ~1s

# ESTRATÃ‰GIA 2: Quality (melhor qualidade)
result_quality = await facade.execute_prompt(
    prompt=prompt,
    strategy="quality",  # Sonnet 4, no cache, 3 attempts
    usage_type="task_generation"
)
# â†’ Model: claude-sonnet-4
# â†’ Cost: ~$0.05
# â†’ Quality: 0.95+

# ESTRATÃ‰GIA 3: Fast (mais rÃ¡pido)
result_fast = await facade.execute_prompt(
    prompt=prompt,
    strategy="fast",  # Haiku, cache-first, 1 attempt
    usage_type="task_generation"
)
# â†’ Model: claude-haiku-3
# â†’ Latency: ~1.5s
# â†’ 1 attempt only

# ESTRATÃ‰GIA 4: Balanced (default)
result_balanced = await facade.execute_prompt(
    prompt=prompt,
    strategy="default",  # Balanceado
    usage_type="task_generation"
)
# â†’ Model: claude-sonnet-4 ou gpt-4o
# â†’ Balance de cost/quality/speed
```

---

## ğŸ§ª Testando Cache

```python
# Primeira execuÃ§Ã£o - cache miss
result1 = await facade.execute_prompt(
    prompt="What are the main features?",
    usage_type="interview",
    temperature=0.7
)
print(f"First: cache_hit={result1['cache_hit']}, cost=${result1['cost']:.4f}")
# Output: First: cache_hit=False, cost=$0.0234

# Segunda execuÃ§Ã£o - cache HIT! âœ…
result2 = await facade.execute_prompt(
    prompt="What are the main features?",  # Mesmo prompt
    usage_type="interview",
    temperature=0.7
)
print(f"Second: cache_hit={result2['cache_hit']}, cost=${result2['cost']:.4f}")
# Output: Second: cache_hit=True, cost=$0.0000

# Economia: 100% em requests repetidos!
```

---

## ğŸ“Š Monitoramento

### Ver EstatÃ­sticas de Cache

```python
stats = facade.cache.get_stats()
print(f"""
Cache Performance:
- Total requests: {stats['total_requests']}
- Cache hits: {stats['cache_hits']}
- Cache misses: {stats['cache_misses']}
- Hit rate: {stats['hit_rate_percent']}
- Exact hits: {stats['exact_hits']}
""")

# Output exemplo apÃ³s 100 requests:
# Cache Performance:
# - Total requests: 100
# - Cache hits: 32
# - Cache misses: 68
# - Hit rate: 32.0%
# - Exact hits: 32
```

### Logs Detalhados

O sistema loga automaticamente:

```
INFO  - âœ“ PrompterFacade enabled - using template-based prompts
INFO  - Using PrompterFacade template-based prompt generation
INFO  - âœ“ Cache HIT (exact) - saved ~$0.0234
INFO  - Selected claude-sonnet-4 (optimize_for=balanced, quality=0.95, latency=3000ms)
INFO  - Execution succeeded on attempt 1, cost=$0.0123, tokens=1234
WARNING - Validation failed for task_generation: ['Response too short']
```

---

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### Customizar Model Selector

```python
from app.prompter.optimization import ModelSelector

selector = ModelSelector()

# Selecionar com constraints
model = selector.select(
    estimated_input_tokens=1000,
    estimated_output_tokens=500,
    max_cost=0.01,        # MÃ¡ximo $0.01
    min_quality=0.85,     # MÃ­nimo 0.85 quality
    max_latency_ms=2000,  # MÃ¡ximo 2s
    optimize_for="balanced"
)
print(f"Selected: {model}")
# Output: Selected: claude-haiku-3

# Ver info do modelo
info = selector.get_model_info("claude-sonnet-4")
print(f"""
Model: {info.name}
Provider: {info.provider}
Quality: {info.quality_score}
Input price: ${info.input_price_per_mtok}/MTok
Output price: ${info.output_price_per_mtok}/MTok
Latency: {info.avg_latency_ms}ms
""")
```

### Criar Validators Customizados

```python
from app.prompter.orchestration.validation import BaseValidator, ValidationResult

class CustomBusinessLogicValidator(BaseValidator):
    """Validator customizado para regras de negÃ³cio"""

    def validate(self, response: str, context: dict) -> ValidationResult:
        # Verificar se contÃ©m palavras-chave obrigatÃ³rias
        required_keywords = ["backend", "frontend", "database"]

        missing = [kw for kw in required_keywords if kw not in response.lower()]

        if missing:
            return ValidationResult.failure(
                errors=[f"Missing required keywords: {missing}"],
                score=0.5
            )

        return ValidationResult.success(score=1.0)

# Usar em pipeline
from app.prompter.orchestration.validation import ValidationPipeline

pipeline = ValidationPipeline([
    EmptyResponseValidator(),
    LengthValidator(min_length=100),
    CustomBusinessLogicValidator(),
])

result = pipeline.validate(response_text, {})
print(f"Valid: {result.passed}, Score: {result.score}")
```

---

## ğŸ¨ Criar Templates Customizados

### Template YAML Personalizado

```yaml
# /backend/app/prompter/templates/custom/my_template.yaml
name: "custom_analysis"
version: 1
category: "user"

# VariÃ¡veis obrigatÃ³rias
variables:
  required:
    - user_input
    - project_context
  optional:
    - additional_notes

# Template com Jinja2
template: |
  Analise o seguinte contexto:

  PROJETO: {{ project_context }}

  INPUT DO USUÃRIO:
  {{ user_input }}

  {% if additional_notes %}
  NOTAS ADICIONAIS:
  {{ additional_notes }}
  {% endif %}

  ForneÃ§a uma anÃ¡lise detalhada em formato JSON.

# Sistema prompt
system_prompt: |
  VocÃª Ã© um analista tÃ©cnico especializado.

# PÃ³s-processamento
post_process:
  - type: "trim_whitespace"
  - type: "validate_json"

tags: ["custom", "analysis"]
estimated_tokens: 1000
recommended_model: "claude-sonnet-4"
```

### Usar Template Customizado

```python
# Renderizar template customizado
rendered = facade.composer.render(
    template_name="custom_analysis",
    variables={
        "user_input": "Preciso de um dashboard",
        "project_context": "E-commerce Laravel + React",
        "additional_notes": "Usar Tailwind CSS"
    }
)

print(rendered)
```

---

## âš ï¸ Troubleshooting

### Cache nÃ£o estÃ¡ funcionando

```python
# Verificar se cache estÃ¡ habilitado
facade = PrompterFacade(db)
if not facade.cache:
    print("âŒ Cache nÃ£o inicializado")
    print("SoluÃ§Ã£o: export PROMPTER_USE_CACHE=true")
else:
    print("âœ… Cache ativo")
    print(facade.cache.get_stats())
```

### Templates nÃ£o carregam

```python
# Verificar composer
if not facade.composer:
    print("âŒ Composer nÃ£o inicializado")
    print("SoluÃ§Ã£o: export PROMPTER_USE_TEMPLATES=true")
else:
    print("âœ… Composer ativo")
    print(f"Template dir: {facade.composer.template_dir}")
```

### Executor falhando

```python
# Ver detalhes do erro
try:
    result = await facade.execute_prompt(prompt="Test", usage_type="test")
except Exception as e:
    print(f"âŒ Error: {e}")
    print(f"Type: {type(e)}")
    import traceback
    traceback.print_exc()
```

---

## ğŸ“ˆ MÃ©tricas Esperadas

ApÃ³s 1000 requests em produÃ§Ã£o:

| MÃ©trica | Sem Prompter | Com Prompter | ReduÃ§Ã£o |
|---------|--------------|--------------|---------|
| **Custo total** | $50.00 | $7.50 | **85%** âœ… |
| **Tokens mÃ©dios/request** | 5000 | 800 | **84%** âœ… |
| **Cache hit rate** | 0% | 32% | **32%** âœ… |
| **Validation pass rate** | 87% | 95% | **+8%** âœ… |
| **Retry success rate** | N/A | 98% | **+98%** âœ… |

---

## ğŸš¦ Migration Path

### Fase 1: HabilitaÃ§Ã£o Gradual (Semana 1-2)

```bash
# Dia 1: Apenas logging
export PROMPTER_USE_TEMPLATES=false
export PROMPTER_USE_CACHE=false
# â†’ Sistema roda em modo legacy, sem mudanÃ§as

# Dia 3: Habilitar templates para 10% do trÃ¡fego
export PROMPTER_USE_TEMPLATES=true
# â†’ Monitorar logs: "Using PrompterFacade template-based..."
# â†’ Comparar custos e qualidade

# Dia 7: Habilitar cache para 10%
export PROMPTER_USE_CACHE=true
# â†’ Monitorar cache hit rate
# â†’ Verificar economia de custos
```

### Fase 2: Rollout Completo (Semana 3-4)

```bash
# Se mÃ©tricas boas apÃ³s 2 semanas:
export PROMPTER_USE_TEMPLATES=true
export PROMPTER_USE_CACHE=true
# â†’ 100% do trÃ¡fego

# Monitorar por 1 semana
# Se estÃ¡vel â†’ sucesso! ğŸ‰
```

---

## ğŸ’¡ Dicas e Best Practices

### 1. **Sempre use cache para prompts repetitivos**
```python
# âœ… GOOD: Habilitar cache
facade = PrompterFacade(db)  # use_cache=True por padrÃ£o
```

### 2. **Escolha a estratÃ©gia certa para o caso de uso**
```python
# ProduÃ§Ã£o crÃ­tica â†’ quality
# Desenvolvimento/testes â†’ cost
# Chat interativo â†’ fast
# Default â†’ balanced
```

### 3. **Monitore cache hit rate**
```python
# Target: >30% hit rate
# Se <20% â†’ revisar padrÃµes de uso
# Se >50% â†’ excelente! ğŸ‰
```

### 4. **Use temperatura=0 para prompts determinÃ­sticos**
```python
# SerÃ¡ cacheado por 30 dias (template cache)
result = await facade.execute_prompt(
    prompt=prompt,
    temperature=0,  # DeterminÃ­stico
    usage_type="code_generation"
)
```

### 5. **Valide sempre as respostas**
```python
# Validation automÃ¡tica por usage_type
# task_generation â†’ JSON + required fields
# interview â†’ length + format
# code_execution â†’ JSON + status field
```

---

## ğŸ“ PrÃ³ximos Passos

1. **Integrar Redis** para cache distribuÃ­do
2. **Habilitar semantic caching** (embeddings)
3. **Implementar A/B testing** de templates
4. **Adicionar Prometheus metrics**
5. **Configurar alertas** (hit rate < 20%, error rate > 5%)

---

## ğŸ“š ReferÃªncias

- **CÃ³digo:** `/backend/app/prompter/`
- **Testes:** `/backend/tests/test_prompter_*.py`
- **Templates:** `/backend/app/prompter/templates/`
- **Plano completo:** `~/.claude/plans/snappy-sprouting-lecun.md`

---

**ğŸ‰ Pronto! VocÃª agora tem um sistema de prompts enterprise-grade!**
